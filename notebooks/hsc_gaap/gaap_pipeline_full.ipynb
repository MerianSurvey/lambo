{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaap pipeline \n",
    "\n",
    "Use this notebook to run `gaap` photometry on Merian-reduced data.\n",
    "\n",
    "Make sure that you are in the right environment! When activating the jupyter notebook:\n",
    "\n",
    "        module load anaconda3/2022.5\n",
    "        . /scratch/gpfs/am2907/Merian/gaap/lambo/scripts/setup_env_w40.sh\n",
    "        jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.butler as dafButler\n",
    "import numpy as np\n",
    "import glob\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getenv('LAMBO_HOME'), 'lambo/scripts/'))\n",
    "from hsc_gaap.deploy_gaap_array import deploy_training_job\n",
    "from hsc_gaap.check_gaap_run import checkRun"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: What patches do we need to reduce?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to identify patches that have the necessary merian data products for `gaap` processing and have not already been processed. Patches need to have:\n",
    "\n",
    "- deepCoadd_ref\n",
    "- deepCoadd_meas\n",
    "- deepCoadd_scarletModelData\n",
    "- deepCoadd_calexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findReducedPatches(tract, band=\"N708\", output_collection='DECam/runs/merian/dr1_wide', skymap='hsc_rings_v1'):\n",
    "        \"\"\"Returns all merian patches for a given tract that have the necessary data products to run gaap\"\"\"\n",
    "\n",
    "        butler = dafButler.Butler('/projects/MERIAN/repo/')\n",
    "        dataId = dict(tract=tract, band=band, skymap=skymap)\n",
    "        \n",
    "        deepCoadd_ref_patches = set([item.dataId[\"patch\"] for item in butler.registry.queryDatasets('deepCoadd_ref', \n",
    "                dataId=dataId, collections=output_collection,\n",
    "                skymap=skymap)])\n",
    "\n",
    "        deepCoadd_meas_patches = set([item.dataId[\"patch\"] for item in butler.registry.queryDatasets('deepCoadd_meas', \n",
    "                dataId=dataId, collections=output_collection,\n",
    "                skymap=skymap)])\n",
    "\n",
    "        deepCoadd_scarletModelData_patches = set([item.dataId[\"patch\"] for item in butler.registry.queryDatasets('deepCoadd_scarletModelData', \n",
    "                dataId=dataId, collections=output_collection,\n",
    "                skymap=skymap)])\n",
    "\n",
    "        deepCoadd_calexp_patches = set([item.dataId[\"patch\"] for item in butler.registry.queryDatasets('deepCoadd_calexp', \n",
    "                dataId=dataId, collections=output_collection,\n",
    "                skymap=skymap)])\n",
    "\n",
    "        del butler\n",
    "\n",
    "        patches = deepCoadd_ref_patches.intersection(deepCoadd_meas_patches, deepCoadd_scarletModelData_patches, deepCoadd_calexp_patches)\n",
    "        return(np.array(list(patches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGaapReducedPatches(tract, repo = '/scratch/gpfs/am2907/Merian/gaap/'):\n",
    "    \"\"\"Returns all merian patches in a given tract that have already \n",
    "       been gaap reduced (have appropriate reduction logs in a given directory)\"\"\"\n",
    "\n",
    "    dir = os.path.join(repo, f\"log/{tract}/\")\n",
    "    logs = np.array(glob.glob(dir + \"*.o\"))\n",
    "    logs_patches = np.array([log.split(\"/\")[-1].split(\".\")[0] for log in logs]).astype(int)\n",
    "    logs, logs_patches = logs[logs_patches.argsort()], logs_patches[logs_patches.argsort()]\n",
    "\n",
    "    return (logs_patches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all Merian tracts with reduced data, and we will search through them to see which patches fit our criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_collection = \"DECam/runs/merian/dr1_wide\"\n",
    "data_type = \"deepCoadd_calexp\"\n",
    "skymap = \"hsc_rings_v1\"\n",
    "butler = dafButler.Butler('/projects/MERIAN/repo/', collections=output_collection, skymap=skymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patches = np.array([[data_id['tract'], data_id[\"patch\"]] for data_id in butler.registry.queryDataIds (['tract','patch'], datasets=data_type, \n",
    "                                                 collections=output_collection, skymap=skymap)])\n",
    "patches = patches[patches[:, 0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts, idx = np.unique(patches[:,0], return_index=True) \n",
    "patches_by_tract = np.split(patches[:,1] ,idx[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_n708 = []\n",
    "for tract in tracts:\n",
    "    patches = \",\".join(findReducedPatches(tract).astype(str))\n",
    "    if len(patches) > 0:\n",
    "        tracts_n708.append(tract)\n",
    "\n",
    "tracts_n708 = np.array(tracts_n708)\n",
    "print(f\"{len(tracts_n708)} tracts with necessary data products\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find patches that haven't yet been `gaap` processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_n708_nogaap = []\n",
    "for tract in tracts:\n",
    "    patches_mer  = findReducedPatches(tract)\n",
    "    patches_gaap = findGaapReducedPatches(tract)\n",
    "    if len(set(patches_mer) - set(patches_gaap)) > 0:\n",
    "        tracts_n708_nogaap.append(tract)\n",
    "        \n",
    "print(f\"{len(tracts_n708_nogaap)} tracts to be reduced\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can see how many patches need to be reduced for each tract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tract in tracts_n708_nogaap:\n",
    "#     patches  = list(set(findReducedPatches(tract))- set(findGaapReducedPatches(tract)))\n",
    "#     if len(patches) > 0:\n",
    "#         print (f'TRACT:{tract}, {len(patches)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Download the data\n",
    "\n",
    "We need to download the HSC data for all of the tracts we need to reduce. *Be warned, this takes a while and uses a lot of storage.*\n",
    "\n",
    "It is recommended to run the following in a bash screen because depending on how much data you need to download, it can take many hours.\n",
    "\n",
    "The following will download images for tract 9813 to `/scratch/gpfs/am2907/Merian/gaap/S20A/deepCoadd_calexp/9813` and the blendedness catalogs to `/scratch/gpfs/am2907/Merian/gaap/S20A/gaapTablecxd`:\n",
    "- Unless `--only_merian=False`, this will only download the patches that have been reduced by Merian.\n",
    "- You can download all of the Merian-reduced data in one go if you set `--alltracts=True`. Be careful with this, because it is ****lots**** of data!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    screen -L -S downloadtract    \n",
    "    \n",
    "    cd /scratch/gpfs/am2907/Merian/gaap\n",
    "    . lambo/scripts/setup_env_w40.sh\n",
    "    python3 lambo/scripts/hsc_gaap/download_S20A.py --tract=9813 --outdir=\"/scratch/gpfs/am2907/Merian/gaap/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To exit screen do `ctrl a d` and to reattach do `screen -r downloaddata`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Make slurm scripts and submit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write one slurm script for each tract – each of which is a job array with one job for each patch. \n",
    "You can submit the scripts as you write them if you want, but beware that there is an upper limit for the number of jobs you can submit at once to the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tract in tracts_n708_nogaap:\n",
    "#     deploy_training_job(tract, filter_jobs=5,\n",
    "#                         python_file='lambo/scripts/hsc_gaap/run_gaap.py',\n",
    "#                         name='gaap', email=\"am2907@princeton.edu\", outname = None, \n",
    "#                         repo='/scratch/gpfs/am2907/Merian/gaap', scriptdir=\"'/scratch/gpfs/am2907/Merian/gaap/\", \n",
    "#                         submit=True, fixpatches=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gaap reduction will save one catalog for each patch to (for example):\n",
    "\n",
    "        /scratch/gpfs/am2907/Merian/gaap/S20A/gaapTable/9813/0,0/objectTable_9813_0,0_S20A.fits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Check on it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check on the logs while the jobs are running to check for any glaring problems:\n",
    "- `logs/gaapPhot_array_9813_0.o` \n",
    "- `logs/gaap_9813_0.log`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One the jobs are done running (for a given tract), you can check how things went. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tract in tracts_n708_nogaap:\n",
    "    problems = checkRun(tract)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might get issues like \"Failed for 3 bands\" - this could be because HSC images don't exist for all bands. So it might not be an issue you can fix!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Merge catalogs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is looking good, you can merge the patch catalogs into a tract-level catalog. \n",
    "\n",
    "It's recommended to run this step in a screen in terminal, because it takes some time!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        python3 lambo/scripts/hsc_gaap/compile_catalogs.py --tracts==\"[9327,9328,9329,9813,9812]\"\n",
    "\n",
    "This will save a catalog to (for example):\n",
    "        \n",
    "        /scratch/gpfs/am2907/Merian/gaap/S20A/gaapTable/9813/objectTable_9813_S20A.fits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to change the columns that are used for the compiled catalog, edit these files:\n",
    "\n",
    "        lambo/scripts/hsc_gaap/keep_table_columns_gaap.txt\n",
    "        lambo/scripts/hsc_gaap/keep_table_columns_merian.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you're all done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
